{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 50000/50000 [12:29<00:00, 66.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.ndimage import imread\n",
    "import codecs\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = 'Cifar Pictures/'\n",
    "output_file = 'cifar_data.txt'\n",
    "\n",
    "with codecs.open(output_file, 'a+', encoding='utf-8') as f:\n",
    "    for image_name in tqdm(os.listdir(input_dir)):\n",
    "        image_data = imread(input_dir + image_name)\n",
    "        image_dict = {image_name: image_data.tolist()}\n",
    "    \n",
    "        json.dump(image_dict, f, separators=(',', ':'))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 cifar_data.txt\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "!wc -l $output_file\n",
    "print(len(os.listdir(input_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mr_cifar.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mr_cifar.py\n",
    "import json\n",
    "import numpy as np\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "\n",
    "class MyMR(MRJob):\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        try:\n",
    "            image_dict = json.loads(line)\n",
    "            ((image_name, image_data),) = image_dict.items()            \n",
    "        except:\n",
    "            assert False, 'something went wrong' # print statements go into mapper output in MRJob\n",
    "            return\n",
    "\n",
    "        color_averages = np.array(image_data).mean(axis=(0, 1))\n",
    "        max_color_channel = np.argmax(color_averages)\n",
    "        yield (int(max_color_channel), (image_name, color_averages[max_color_channel]))\n",
    "        # key has to be int, not np.int64\n",
    "    \n",
    "    def reducer(self, max_color_channel, max_color_intensities):\n",
    "        yield max_color_channel, sorted(max_color_intensities, key=lambda tup: (-tup[1], tup[0]))\n",
    "\n",
    "        \n",
    "if __name__ == '__main__': \n",
    "    MyMR.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_cifar.Eugene.20170718.041451.859000\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "Streaming final output from c:\\users\\eugene\\appdata\\local\\temp\\mr_cifar.Eugene.20170718.041451.859000\\output...\n",
      "Removing temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_cifar.Eugene.20170718.041451.859000...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python mr_cifar.py < cifar_data.txt > temp_MRJob.txt\n",
    "# python cifar_map_reduce.py --mapper < cifar_data.txt # just run mapper\n",
    "# sort temp.txt > temp0.txt\n",
    "# python cifar_map_reduce.py --reducer < temp0.txt > temp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# just run mapper and reducer separately\n",
    "!python mr_cifar.py --mapper < cifar_data.txt > temp_mapper_output.txt\n",
    "!sort temp_mapper_output.txt > temp_mapper_output_sorted.txt\n",
    "!python mr_cifar.py --reducer < temp_mapper_output_sorted.txt > temp_reducer_output.txt\n",
    "!diff temp_reducer_output.txt temp_MRJob.txt\n",
    "\n",
    "# 1 liner\n",
    "#!cat cifar_data.txt | python cifar_map_reduce.py --mapper | \\\n",
    "#sort | python cifar_map_reduce.py --reducer > temp_reducer_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_channels_and_pictures = dict()\n",
    "with open('temp_MRJob.txt') as f:\n",
    "    for line in f:\n",
    "        color_channel, images_and_intensities = line.split('\\t')\n",
    "        images_and_intensities = eval(images_and_intensities)\n",
    "        image_names = [image_name for image_name, color_intensity in images_and_intensities]        \n",
    "        color_channels_and_pictures[color_channel] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "from scipy.ndimage import imread\n",
    "import numpy as np\n",
    "\n",
    "def plots(ims, interp=False, titles=None):\n",
    "    ims=np.array(ims)\n",
    "    mn,mx=ims.min(),ims.max()\n",
    "    f = plt.figure(figsize=(12,24))\n",
    "    for i in range(len(ims)):\n",
    "        sp=f.add_subplot(1, len(ims), i+1)\n",
    "        if not titles is None: sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none', vmin=mn,vmax=mx)\n",
    "\n",
    "def plot(im, interp=False):\n",
    "    f = plt.figure(figsize=(3,6), frameon=True)\n",
    "    plt.imshow(im, interpolation=None if interp else 'none')\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = 'Cifar Pictures/'\n",
    "\n",
    "channel_images = []\n",
    "for image_name in color_channels_and_pictures['1'][:10]: # key becomes string\n",
    "    channel_images.append(imread(input_dir + image_name))\n",
    "\n",
    "plots(channel_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual EMR Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting EMR_cifar_mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile EMR_cifar_mapper.py\n",
    "#!/usr/bin/python\n",
    "# OUTPUT: max_color_channel \\t image_name \\t max_color_intensity\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "for line in sys.stdin:\n",
    "    image_dict = json.loads(line)    \n",
    "    try:\n",
    "        image_dict = json.loads(line)\n",
    "        ((image_name, image_data),) = image_dict.items()            \n",
    "    except:\n",
    "        assert False, 'something went wrong'\n",
    "\n",
    "    color_averages = np.array(image_data).mean(axis=(0, 1))\n",
    "    max_color_channel = np.argmax(color_averages)\n",
    "    print(\"{}\\t{}\\t{}\".format(\n",
    "        int(max_color_channel), \n",
    "        image_name, \n",
    "        color_averages[max_color_channel]))\n",
    "        # key has to be int, not np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting EMR_cifar_reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile EMR_cifar_reducer.py\n",
    "#!/usr/bin/python\n",
    "# OUTPUT: color_channel \\t sorted_image_name_color_intensity_tuple\n",
    "\n",
    "import sys\n",
    "\n",
    "current_color_channel = None\n",
    "image_names_color_intensities = None\n",
    "\n",
    "for line in sys.stdin: # everything read in is a string!\n",
    "    max_color_channel, image_name, max_color_intensity = line.strip().split('\\t')\n",
    "    if current_color_channel == max_color_channel:\n",
    "        image_names_color_intensities.append(\n",
    "            (image_name, float(max_color_intensity))\n",
    "            )\n",
    "    else:\n",
    "        if current_color_channel: # if channel changes, print results\n",
    "            print(\"{}\\t{}\".format(\n",
    "                current_color_channel, \n",
    "                sorted(image_names_color_intensities, key=lambda tup: (-tup[1], tup[0])) # for breaking ties\n",
    "                ))\n",
    "        current_color_channel = max_color_channel\n",
    "        image_names_color_intensities = []\n",
    "        image_names_color_intensities.append(\n",
    "            (image_name, float(max_color_intensity))\n",
    "        )\n",
    "        \n",
    "if current_color_channel: # for last color channel\n",
    "    print(\"{}\\t{}\".format(current_color_channel, \n",
    "        sorted(image_names_color_intensities, key=lambda tup: (-tup[1], tup[0])) # for breaking ties\n",
    "         ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#!python EMR_mapper.py < cifar_data.txt > temp1.txt\n",
    "#!sort temp1.txt > temp2.txt\n",
    "#!python EMR_reducer.py < temp2.txt > temp3.txt\n",
    "\n",
    "# 1 liner\n",
    "!cat cifar_data.txt | python EMR_cifar_mapper.py | sort | python EMR_cifar_reducer.py > temp_cifar_EMR_manual.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dos2unix: converting file EMR_cifar_mapper.py to Unix format...\n",
      "dos2unix: converting file EMR_cifar_mapper.py to Unix format...\n",
      "dos2unix: converting file EMR_cifar_reducer.py to Unix format...\n",
      "dos2unix: converting file EMR_cifar_reducer.py to Unix format...\n"
     ]
    }
   ],
   "source": [
    "# to put on EMR if you are on Windows, convert Windows file to Linux compatible\n",
    "!dos2unix EMR_cifar_mapper.py EMR_cifar_mapper.py\n",
    "!dos2unix EMR_cifar_reducer.py EMR_cifar_reducer.py\n",
    "\n",
    "# optional\n",
    "!chmod +x EMR_cifar_mapper.py\n",
    "!chmod +x EMR_cifar_reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Elastic MapReduce Notes\n",
    "\n",
    "## Sorting\n",
    "* When there exist ties, the EMR sort might not be identical to MRJob or manual sort. Hence, you want to sort in a way that is deterministic to always break ties--if consistency is your goal.\n",
    "\n",
    "## Cluster Creation under \"Advanced Options\",\n",
    "* On \"Software Configuration\", set \"Step type\" to \"Streaming program\"  \n",
    "* On \"Hardware Configuration\", set \"EC2 Subnet\" to subregion that has the EC2 instances that you want, i.e. us-east-1e. Also, select number of EC2 instances you want for Master and Core nodes \n",
    "* On \"General Options\", name your cluster and select correct folder for S3 folder Logging\n",
    "* On \"Security Options\", select your EC2 key pair if you want to ssh into it\n",
    "\n",
    "## Cluster Debugging\n",
    "\n",
    "* To ssh, `ssh -i key.pem hadoop@ec2-54-236-17-44.compute-1.amazonaws.com` where the instance is shown under \"Master public DNS\". If you have any problems ssh into Hadoop instance, perhaps you have to open port 22\n",
    "* EMR instances have Python 2 and 3 installed along with many libraries. You can ssh into to see which ones are available\n",
    "* When setting up \"Steps\" with \"Add step\", when things break, look under 'syslog'.\n",
    "* For seeing how the cluster is doing, inside 'steps', look at 'View jobs' to see where things are progressing. Can even look at \"View tasks\".\n",
    "* When \"Adding step\", select the input folder is better than a single file, unless you want only that 1 file.\n",
    "* For output_folder, have to create a new one every single time. Hence, navigate to where you want to set up folder. Then, type an inner folder name that doesn't exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download EMR results from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto\n",
    "\n",
    "AWS_credentials = {}\n",
    "with open('rootkey.csv') as f:\n",
    "    for line in f:\n",
    "        if 'AWSAccessKeyId' in line:\n",
    "            AWS_credentials['aws_access_key_id'] = line.strip().split('=')[1]\n",
    "        elif 'AWSSecretKey' in line:\n",
    "            AWS_credentials['aws_secret_access_key'] = line.strip().split('=')[1]\n",
    "\n",
    "conn = boto.connect_s3(**AWS_credentials)\n",
    "bucket = conn.get_bucket('map-reduce-practice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_data/cifar/_SUCCESS\n",
      "output_data/cifar/part-00000\n",
      "output_data/cifar/part-00001\n",
      "output_data/cifar/part-00002\n",
      "output_data/cifar/part-00003\n",
      "output_data/cifar/part-00004\n",
      "output_data/cifar/part-00005\n",
      "output_data/cifar/part-00006\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = 'output_data/cifar/'\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for key in bucket.list():\n",
    "    if output_dir in key.key:\n",
    "        print key.key\n",
    "        file_name = key.key.split('/')[-1]\n",
    "        key.get_contents_to_filename(output_dir + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if MRJob, manual map-reduce, EMR results match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_channels_and_pictures = dict()\n",
    "with open('temp_MRJob.txt') as f:\n",
    "    for line in f:\n",
    "        color_channel, images_and_intensities = line.split('\\t')\n",
    "        images_and_intensities = eval(images_and_intensities)\n",
    "        image_names = [image_name for image_name, color_intensity in images_and_intensities]        \n",
    "        color_channels_and_pictures[color_channel] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_channels_and_pictures_manual = dict()\n",
    "with open('temp_cifar_EMR_manual.txt') as f:\n",
    "    for line in f:\n",
    "        color_channel, images_and_intensities = line.split('\\t')\n",
    "        images_and_intensities = eval(images_and_intensities)\n",
    "        image_names = [image_name for image_name, color_intensity in images_and_intensities]        \n",
    "        color_channels_and_pictures_manual[color_channel] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(color_channels_and_pictures == color_channels_and_pictures_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = 'output_data/cifar/'\n",
    "color_channels_and_pictures_EMR = dict()\n",
    "\n",
    "for file_name in os.listdir(output_dir):\n",
    "    with open(output_dir + file_name) as f:\n",
    "        for line in f:\n",
    "            color_channel, images_and_intensities = line.split('\\t')\n",
    "            images_and_intensities = eval(images_and_intensities)\n",
    "            print(cheat_sort(images_and_intensities) == color_channels_and_pictures[color_channel])\n",
    "            image_names = [image_name for image_name, color_intensity in images_and_intensities]        \n",
    "            color_channels_and_pictures_EMR[color_channel] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(color_channels_and_pictures == color_channels_and_pictures_EMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = 'output_data/cifar/'\n",
    "color_channels_and_pictures_EMR = dict()\n",
    "\n",
    "for file_name in os.listdir(output_dir):\n",
    "    with open(output_dir + file_name) as f:\n",
    "        for line in f:\n",
    "            color_channel, images_and_intensities = line.split('\\t')\n",
    "            images_and_intensities = eval(images_and_intensities)\n",
    "            image_names = [image_name for image_name, color_intensity in images_and_intensities]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229 230 487 488 683 684 719 720 876 877 899 900]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "disagreement = np.where(np.array(color_channels_and_pictures_manual['2'][:1000]) != \n",
    "                        np.array(color_channels_and_pictures_EMR['2'][:1000]))[0]\n",
    "print disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22642.png' '42242.png' '20380.png' '4553.png' '29079.png' '47747.png'\n",
      " '1146.png' '47382.png' '21119.png' '45345.png' '12312.png' '45011.png']\n",
      "['42242.png' '22642.png' '4553.png' '20380.png' '47747.png' '29079.png'\n",
      " '47382.png' '1146.png' '45345.png' '21119.png' '45011.png' '12312.png']\n"
     ]
    }
   ],
   "source": [
    "print np.array(color_channels_and_pictures_manual['2'])[disagreement]\n",
    "print np.array(color_channels_and_pictures_EMR['2'])[disagreement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def cheat_sort(lst):\n",
    "    re_sort = defaultdict(list)\n",
    "    for tup in lst:\n",
    "        re_sort[tup[1]].append(tup[0])\n",
    "        \n",
    "    results = []\n",
    "    for intensity in sorted(re_sort, reverse=True):\n",
    "        results.extend(re_sort[intensity])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheat_sort(images_and_intensities)[:100] == color_channels_and_pictures_manual['2'][:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
