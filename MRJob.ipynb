{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 50000/50000 [12:29<00:00, 66.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.ndimage import imread\n",
    "import codecs\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = 'Cifar Pictures/'\n",
    "output_file = 'cifar_data.txt'\n",
    "\n",
    "with codecs.open(output_file, 'a+', encoding='utf-8') as f:\n",
    "    for image_name in tqdm(os.listdir(input_dir)):\n",
    "        image_data = imread(input_dir + image_name)\n",
    "        image_dict = {image_name: image_data.tolist()}\n",
    "    \n",
    "        json.dump(image_dict, f, separators=(',', ':'))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 cifar_data.txt\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "!wc -l $output_file\n",
    "print(len(os.listdir(input_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cifar_map_reduce.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cifar_map_reduce.py\n",
    "import json\n",
    "import numpy as np\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "\n",
    "class MyMR(MRJob):\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        try:\n",
    "            image_dict = json.loads(line)\n",
    "            ((image_name, image_data),) = image_dict.items()            \n",
    "        except:\n",
    "            assert False, 'something went wrong' # print statements go into mapper output in MRJob\n",
    "            return\n",
    "\n",
    "        color_averages = np.array(image_data).mean(axis=(0, 1))\n",
    "        max_color_channel = np.argmax(color_averages)\n",
    "        yield (int(max_color_channel), (image_name, color_averages[max_color_channel]))\n",
    "        # key has to be int, not np.int64\n",
    "    \n",
    "    def reducer(self, max_color_channel, max_color_intensities):\n",
    "        yield max_color_channel, sorted(max_color_intensities, key=lambda tup: -tup[1])\n",
    "\n",
    "        \n",
    "if __name__ == '__main__': \n",
    "    MyMR.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory c:\\users\\eugene\\appdata\\local\\temp\\cifar_map_reduce.Eugene.20170717.030616.851000\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "Streaming final output from c:\\users\\eugene\\appdata\\local\\temp\\cifar_map_reduce.Eugene.20170717.030616.851000\\output...\n",
      "Removing temp directory c:\\users\\eugene\\appdata\\local\\temp\\cifar_map_reduce.Eugene.20170717.030616.851000...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python cifar_map_reduce.py < cifar_data.txt > temp_MRJob.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_channels_and_pictures = dict()\n",
    "with open('temp_MRJob.txt') as f:\n",
    "    for line in f:\n",
    "        color_channel, images_and_intensities = line.split('\\t')\n",
    "        images_and_intensities = eval(images_and_intensities)\n",
    "        image_names = [image_name for image_name, color_intensity in images_and_intensities]        \n",
    "        color_channels_and_pictures[color_channel] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "from scipy.ndimage import imread\n",
    "import numpy as np\n",
    "\n",
    "def plots(ims, interp=False, titles=None):\n",
    "    ims=np.array(ims)\n",
    "    mn,mx=ims.min(),ims.max()\n",
    "    f = plt.figure(figsize=(12,24))\n",
    "    for i in range(len(ims)):\n",
    "        sp=f.add_subplot(1, len(ims), i+1)\n",
    "        if not titles is None: sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none', vmin=mn,vmax=mx)\n",
    "\n",
    "def plot(im, interp=False):\n",
    "    f = plt.figure(figsize=(3,6), frameon=True)\n",
    "    plt.imshow(im, interpolation=None if interp else 'none')\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = 'Cifar Pictures/'\n",
    "\n",
    "channel_images = []\n",
    "for image_name in color_channels_and_pictures['1'][:20]: # key becomes string\n",
    "    channel_images.append(imread(input_dir + image_name))\n",
    "\n",
    "plots(channel_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Map and Reduce Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing EMR_mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile EMR_mapper.py\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "for line in sys.stdin:\n",
    "    image_dict = json.loads(line)    \n",
    "    try:\n",
    "        image_dict = json.loads(line)\n",
    "        ((image_name, image_data),) = image_dict.items()            \n",
    "    except:\n",
    "        assert False, 'something went wrong'\n",
    "\n",
    "    color_averages = np.array(image_data).mean(axis=(0, 1))\n",
    "    max_color_channel = np.argmax(color_averages)\n",
    "    print(\"{}\\t{}\\t{}\".format(\n",
    "        int(max_color_channel), \n",
    "        image_name, \n",
    "        color_averages[max_color_channel]))\n",
    "        # key has to be int, not np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing EMR_reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile EMR_reducer.py\n",
    "import sys\n",
    "\n",
    "current_color_channel = None\n",
    "image_names_color_intensities = None\n",
    "\n",
    "for line in sys.stdin: # everything read in is a string!\n",
    "    max_color_channel, image_name, max_color_intensity = line.strip().split('\\t')\n",
    "    if current_color_channel == max_color_channel:\n",
    "        image_names_color_intensities.append(\n",
    "            (image_name, float(max_color_intensity))\n",
    "            )\n",
    "    else:\n",
    "        if current_color_channel: # if channel changes, print results\n",
    "            print(\"{}\\t{}\".format(\n",
    "                current_color_channel, \n",
    "                sorted(image_names_color_intensities, key=lambda tup: -tup[1])\n",
    "                ))\n",
    "        current_color_channel = max_color_channel\n",
    "        image_names_color_intensities = []\n",
    "        image_names_color_intensities.append(\n",
    "            (image_name, float(max_color_intensity))\n",
    "        )\n",
    "        \n",
    "if current_color_channel: # for last color channel\n",
    "    print(\"{}\\t{}\".format(current_color_channel, sorted(\n",
    "                image_names_color_intensities, key=lambda tup: -tup[1])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python EMR_mapper.py < cifar_data.txt > temp1.txt\n",
    "!sort temp1.txt > temp2.txt\n",
    "!python EMR_reducer.py < temp2.txt > temp3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if MRJob and manual map-reduce results match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_channels_and_pictures = dict()\n",
    "with open('temp_MRJob.txt') as f:\n",
    "    for line in f:\n",
    "        color_channel, images_and_intensities = line.split('\\t')\n",
    "        images_and_intensities = eval(images_and_intensities)\n",
    "        image_names = [image_name for image_name, color_intensity in images_and_intensities]        \n",
    "        color_channels_and_pictures[color_channel] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_channels_and_pictures_manual = dict()\n",
    "with open('temp3.txt') as f:\n",
    "    for line in f:\n",
    "        color_channel, images_and_intensities = line.split('\\t')\n",
    "        images_and_intensities = eval(images_and_intensities)\n",
    "        image_names = [image_name for image_name, color_intensity in images_and_intensities]        \n",
    "        color_channels_and_pictures_manual[color_channel] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(color_channels_and_pictures == color_channels_and_pictures_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mr_word_count.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mr_word_count.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        yield \"chars\", len(line)\n",
    "        yield \"words\", len(line.split())\n",
    "        yield \"lines\", 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"chars\"\t5333743\n",
      "\"lines\"\t124456\n",
      "\"words\"\t901325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_word_count.Eugene.20170717.031112.880000\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "Streaming final output from c:\\users\\eugene\\appdata\\local\\temp\\mr_word_count.Eugene.20170717.031112.880000\\output...\n",
      "Removing temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_word_count.Eugene.20170717.031112.880000...\n"
     ]
    }
   ],
   "source": [
    "!python mr_word_count.py < shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mr_word_counter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mr_word_counter.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.lower().split():\n",
    "            yield (word, 1)\n",
    "\n",
    "    def combiner(self, word, aggregated_counts):\n",
    "        yield word, sum(aggregated_counts)\n",
    "\n",
    "    def reducer(self, key, count):\n",
    "        yield key, sum(count)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_word_counter.Eugene.20170717.031118.295000\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "Streaming final output from c:\\users\\eugene\\appdata\\local\\temp\\mr_word_counter.Eugene.20170717.031118.295000\\output...\n",
      "Removing temp directory c:\\users\\eugene\\appdata\\local\\temp\\mr_word_counter.Eugene.20170717.031118.295000...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\"\t27549\n",
      "\"and\"\t26037\n",
      "\"i\"\t19540\n",
      "\"to\"\t18700\n",
      "\"of\"\t18010\n",
      "\"a\"\t14383\n",
      "\"my\"\t12455\n",
      "\"in\"\t10671\n",
      "\"you\"\t10630\n",
      "\"that\"\t10487\n",
      "\"is\"\t9145\n",
      "\"for\"\t7982\n",
      "\"with\"\t7931\n",
      "\"not\"\t7643\n",
      "\"your\"\t6871\n",
      "\"his\"\t6749\n",
      "\"be\"\t6700\n",
      "\"but\"\t5886\n",
      "\"he\"\t5884\n",
      "\"as\"\t5882\n",
      "Wall time: 12.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sort: write failed: 'standard output'\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python mr_word_counter.py < shakespeare.txt > temp_shakespeare_counter_results.txt\n",
    "!cat temp_shakespeare_counter_results.txt | sort --key 2nr -n | head -20\n",
    "# sort by second key in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 27549), ('and', 26037), ('i', 19540), ('to', 18700), ('of', 18010), ('a', 14383), ('my', 12455), ('in', 10671), ('you', 10630), ('that', 10487)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_manual = Counter()\n",
    "with open('shakespeare.txt') as f:\n",
    "    for line in f:\n",
    "        counter_manual.update(line.lower().split())\n",
    "\n",
    "print(counter_manual.most_common()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 27549), ('and', 26037), ('i', 19540), ('to', 18700), ('of', 18010), ('a', 14383), ('my', 12455), ('in', 10671), ('you', 10630), ('that', 10487)]\n"
     ]
    }
   ],
   "source": [
    "counter_mapreduce = Counter()\n",
    "\n",
    "with open('temp_shakespeare_counter_results.txt') as f:\n",
    "    for line in f:\n",
    "        word, count = line.strip().split('\\t')\n",
    "        counter_mapreduce[word.strip('\"')] = int(count)\n",
    "\n",
    "print(counter_mapreduce.most_common()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 241),\n",
       " ('\"a', 4),\n",
       " ('\"i', 4),\n",
       " ('sail!\"', 3),\n",
       " ('print!\"', 3),\n",
       " ('\"small', 3),\n",
       " ('\"caesar.\"', 2),\n",
       " ('\"thus', 2),\n",
       " ('\"fear', 2),\n",
       " ('\"give', 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(counter_manual - counter_mapreduce).most_common()[:10]\n",
    "# close enough!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
